{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Train and compare the performance of residential location choice models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functions import set_seed, train, evaluate_nn, Config\n",
    "from models import MNL_Choice, SCL_Choice, GNNChoiceModel, MLP_Choice\n",
    "from data_process import load_data, spatial_choice_dataset_interact\n",
    "comm, hh, edge_index, distance_to_work = load_data()\n",
    "\n",
    "comm_features = [\n",
    "    \"pop_density\",\n",
    "    \"white_prop\",\n",
    "    \"black_prop\",\n",
    "    \"single_res\",\n",
    "    \"multi_res\",\n",
    "    \"office\",\n",
    "    \"retail\",\n",
    "    \"land_mix\",\n",
    "    \"transit_a_scaled\",\n",
    "    \"med_house_age_scaled\",\n",
    "    \"med_value_scaled\",\n",
    "    \"h_units_scaled\",\n",
    "    \"median_inc_scaled\",\n",
    "]\n",
    "\n",
    "hh_features = [\"hh_income_scaled\", \"race_white\", \"race_black\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLL_train: -11566.5605 \t LLL_test: -1350.1887 \t         accuracy_train: 0.1384 \t accuracy_test: 0.1094 \t         Fold: 1/10\n",
      "LLL_train: -11564.4082 \t LLL_test: -1333.9615 \t         accuracy_train: 0.1395 \t accuracy_test: 0.0990 \t         Fold: 2/10\n",
      "LLL_train: -11558.5752 \t LLL_test: -1326.8843 \t         accuracy_train: 0.1367 \t accuracy_test: 0.1458 \t         Fold: 3/10\n",
      "LLL_train: -11613.8643 \t LLL_test: -1313.5713 \t         accuracy_train: 0.1364 \t accuracy_test: 0.1276 \t         Fold: 4/10\n",
      "LLL_train: -11607.5010 \t LLL_test: -1284.3704 \t         accuracy_train: 0.1346 \t accuracy_test: 0.1641 \t         Fold: 5/10\n",
      "LLL_train: -11612.0410 \t LLL_test: -1329.2964 \t         accuracy_train: 0.1387 \t accuracy_test: 0.1172 \t         Fold: 6/10\n",
      "LLL_train: -11564.8408 \t LLL_test: -1311.0835 \t         accuracy_train: 0.1361 \t accuracy_test: 0.1016 \t         Fold: 7/10\n",
      "LLL_train: -11628.8145 \t LLL_test: -1267.0181 \t         accuracy_train: 0.1335 \t accuracy_test: 0.1589 \t         Fold: 8/10\n",
      "LLL_train: -11591.5020 \t LLL_test: -1312.5654 \t         accuracy_train: 0.1357 \t accuracy_test: 0.1462 \t         Fold: 9/10\n",
      "LLL_train: -11650.5859 \t LLL_test: -1292.6478 \t         accuracy_train: 0.1381 \t accuracy_test: 0.1332 \t         Fold: 10/10\n",
      "Train results mean: \n",
      "f1                 0.057581\n",
      "accuracy           0.136761\n",
      "MRR                0.275848\n",
      "top_3              0.290863\n",
      "top_5              0.405941\n",
      "top_10             0.611111\n",
      "error_d            7.040635\n",
      "error_d_avg        9.038797\n",
      "LLL           -11595.869141\n",
      "dtype: float64\n",
      "Test results mean: \n",
      "f1                0.044289\n",
      "accuracy          0.130281\n",
      "MRR               0.264510\n",
      "top_3             0.273320\n",
      "top_5             0.388230\n",
      "top_10            0.587552\n",
      "error_d           7.123984\n",
      "error_d_avg       9.077873\n",
      "LLL           -1312.158813\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set the training and evaluation procedure\n",
    "device = torch.device(\"cpu\")\n",
    "config = Config()\n",
    "config.bs = 32\n",
    "config.num_hidden = 64\n",
    "config.dropout = 0\n",
    "config.optimizer = \"adam\"  # one of [adam, sgd]\n",
    "config.lr = 0.01\n",
    "config.lr_scheduler = \"one_cycle\"  # one of [step, one_cycle, exp, none]\n",
    "config.n_epoch = 20\n",
    "config.model = \"GATConv\"  # or any other model name\n",
    "config.heads = 4  # Number of attention heads for GAT\n",
    "config.mode = \"disabled\"  # online or disabled\n",
    "config.residual = True\n",
    "config.seed = 100\n",
    "\n",
    "my_dataset = spatial_choice_dataset_interact\n",
    "train_results = []\n",
    "test_results = []\n",
    "for i in range(10):\n",
    "    test_idx = np.arange(i, len(hh), 10)\n",
    "    train_idx = np.setdiff1d(np.arange(len(hh)), test_idx)\n",
    "    train_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[train_idx, :],\n",
    "        distance_to_work[train_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "    test_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[test_idx, :],\n",
    "        distance_to_work[test_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config.bs, shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=len(test_dataset), shuffle=False\n",
    "    )\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = GNNChoiceModel(\n",
    "        train_dataset[0][0].shape[-1],\n",
    "        config.num_hidden,\n",
    "        edge_index,\n",
    "        dropout=config.dropout,\n",
    "        heads=config.heads,\n",
    "        residual=config.residual,\n",
    "    ).to(device)\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = train(\n",
    "        model,\n",
    "        criterion,\n",
    "        train_loader,\n",
    "        None,\n",
    "        test_loader,\n",
    "        config,\n",
    "        device,\n",
    "        verbose=False,\n",
    "    )\n",
    "    train_results.append(evaluate_nn(model, train_loader, comm))\n",
    "    test_results.append(evaluate_nn(model, test_loader, comm))\n",
    "\n",
    "    print(\n",
    "        f\"LLL_train: {train_results[-1]['LLL']:.4f} \\t LLL_test: {test_results[-1]['LLL']:.4f} \\t \\\n",
    "        accuracy_train: {train_results[-1]['accuracy']:.4f} \\t accuracy_test: {test_results[-1]['accuracy']:.4f} \\t \\\n",
    "        Fold: {i + 1}/10\"\n",
    "    )  # Log the results\n",
    "\n",
    "train_results = {\n",
    "    key: [d[key] for d in train_results] for key in train_results[0].keys()\n",
    "}\n",
    "test_results = {\n",
    "    key: [d[key] for d in test_results] for key in test_results[0].keys()\n",
    "}\n",
    "train_results = pd.DataFrame(train_results)\n",
    "test_results = pd.DataFrame(test_results)\n",
    "train_results.to_csv(f\"results/{config.model}_train_results.csv\", index=False)\n",
    "test_results.to_csv(f\"results/{config.model}_test_results.csv\", index=False)\n",
    "\n",
    "print(f\"Train results mean: \\n{train_results.mean()}\")\n",
    "print(f\"Test results mean: \\n{test_results.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLL_train: -11756.6230 \t LLL_test: -1352.9230 \t         accuracy_train: 0.1283 \t accuracy_test: 0.1172 \t         Fold: 1/10\n",
      "LLL_train: -11761.9961 \t LLL_test: -1351.3311 \t         accuracy_train: 0.1314 \t accuracy_test: 0.0964 \t         Fold: 2/10\n",
      "LLL_train: -11758.9531 \t LLL_test: -1341.5723 \t         accuracy_train: 0.1265 \t accuracy_test: 0.1302 \t         Fold: 3/10\n",
      "LLL_train: -11800.4072 \t LLL_test: -1317.3148 \t         accuracy_train: 0.1265 \t accuracy_test: 0.1276 \t         Fold: 4/10\n",
      "LLL_train: -11814.6699 \t LLL_test: -1296.9275 \t         accuracy_train: 0.1210 \t accuracy_test: 0.1562 \t         Fold: 5/10\n",
      "LLL_train: -11775.7949 \t LLL_test: -1335.1088 \t         accuracy_train: 0.1323 \t accuracy_test: 0.1016 \t         Fold: 6/10\n",
      "LLL_train: -11772.7666 \t LLL_test: -1321.4036 \t         accuracy_train: 0.1314 \t accuracy_test: 0.1016 \t         Fold: 7/10\n",
      "LLL_train: -11823.1211 \t LLL_test: -1280.6267 \t         accuracy_train: 0.1251 \t accuracy_test: 0.1484 \t         Fold: 8/10\n",
      "LLL_train: -11787.7451 \t LLL_test: -1314.3784 \t         accuracy_train: 0.1271 \t accuracy_test: 0.1332 \t         Fold: 9/10\n",
      "LLL_train: -11817.1348 \t LLL_test: -1288.1152 \t         accuracy_train: 0.1305 \t accuracy_test: 0.1123 \t         Fold: 10/10\n",
      "Train results mean: \n",
      "f1                 0.055077\n",
      "accuracy           0.128018\n",
      "MRR                0.263329\n",
      "top_3              0.274941\n",
      "top_5              0.384720\n",
      "top_10             0.593393\n",
      "error_d            7.460897\n",
      "error_d_avg        9.213484\n",
      "LLL           -11786.919922\n",
      "dtype: float64\n",
      "Test results mean: \n",
      "f1                0.044768\n",
      "accuracy          0.122460\n",
      "MRR               0.256928\n",
      "top_3             0.267588\n",
      "top_5             0.377289\n",
      "top_10            0.579738\n",
      "error_d           7.479910\n",
      "error_d_avg       9.233639\n",
      "LLL           -1319.970093\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set the training and evaluation procedure\n",
    "config = Config()\n",
    "config.bs = 32\n",
    "config.num_hidden = 64\n",
    "config.dropout = 0\n",
    "config.optimizer = \"adam\"  # one of [adam, sgd]\n",
    "config.lr = 0.01\n",
    "config.lr_scheduler = \"one_cycle\"  # one of [step, one_cycle, exp, none]\n",
    "config.n_epoch = 20\n",
    "config.model = \"MLP\"  # or any other model name\n",
    "config.mode = \"disabled\"  # online or disabled\n",
    "config.seed = 100\n",
    "my_dataset = spatial_choice_dataset_interact\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "for i in range(10):\n",
    "    test_idx = np.arange(i, len(hh), 10)\n",
    "    train_idx = np.setdiff1d(np.arange(len(hh)), test_idx)\n",
    "    train_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[train_idx, :],\n",
    "        distance_to_work[train_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "    test_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[test_idx, :],\n",
    "        distance_to_work[test_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config.bs, shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=len(test_dataset), shuffle=False\n",
    "    )\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = MLP_Choice(\n",
    "        train_dataset[0][0].shape[-1], config.num_hidden, config.dropout\n",
    "    ).to(device)\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = train(\n",
    "        model,\n",
    "        criterion,\n",
    "        train_loader,\n",
    "        None,\n",
    "        test_loader,\n",
    "        config,\n",
    "        device,\n",
    "        verbose=False,\n",
    "    )\n",
    "    train_results.append(evaluate_nn(model, train_loader, comm))\n",
    "    test_results.append(evaluate_nn(model, test_loader, comm))\n",
    "\n",
    "    print(\n",
    "        f\"LLL_train: {train_results[-1]['LLL']:.4f} \\t LLL_test: {test_results[-1]['LLL']:.4f} \\t \\\n",
    "        accuracy_train: {train_results[-1]['accuracy']:.4f} \\t accuracy_test: {test_results[-1]['accuracy']:.4f} \\t \\\n",
    "        Fold: {i + 1}/10\"\n",
    "    )  # Log the results\n",
    "\n",
    "train_results = {\n",
    "    key: [d[key] for d in train_results] for key in train_results[0].keys()\n",
    "}\n",
    "test_results = {key: [d[key] for d in test_results] for key in test_results[0].keys()}\n",
    "train_results = pd.DataFrame(train_results)\n",
    "test_results = pd.DataFrame(test_results)\n",
    "train_results.to_csv(f\"results/{config.model}_train_results.csv\", index=False)\n",
    "test_results.to_csv(f\"results/{config.model}_test_results.csv\", index=False)\n",
    "\n",
    "print(f\"Train results mean: \\n{train_results.mean()}\")\n",
    "print(f\"Test results mean: \\n{test_results.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLL_train: -11981.8516 \t LLL_test: -1360.5092 \t         accuracy_train: 0.1233 \t accuracy_test: 0.1094 \t         Fold: 1/10\n",
      "Estimated mu value=0.9999631643295288\n",
      "LLL_train: -11996.9883 \t LLL_test: -1344.0950 \t         accuracy_train: 0.1236 \t accuracy_test: 0.1094 \t         Fold: 2/10\n",
      "Estimated mu value=0.999929666519165\n",
      "LLL_train: -11975.9453 \t LLL_test: -1366.6655 \t         accuracy_train: 0.1248 \t accuracy_test: 0.1224 \t         Fold: 3/10\n",
      "Estimated mu value=0.9999314546585083\n",
      "LLL_train: -11988.4316 \t LLL_test: -1354.8347 \t         accuracy_train: 0.1257 \t accuracy_test: 0.1224 \t         Fold: 4/10\n",
      "Estimated mu value=0.9999300241470337\n",
      "LLL_train: -12026.8535 \t LLL_test: -1315.6599 \t         accuracy_train: 0.1184 \t accuracy_test: 0.1484 \t         Fold: 5/10\n",
      "Estimated mu value=0.9999678134918213\n",
      "LLL_train: -11981.1895 \t LLL_test: -1360.4285 \t         accuracy_train: 0.1265 \t accuracy_test: 0.1016 \t         Fold: 6/10\n",
      "Estimated mu value=0.9999291896820068\n",
      "LLL_train: -11995.2080 \t LLL_test: -1347.7189 \t         accuracy_train: 0.1262 \t accuracy_test: 0.1146 \t         Fold: 7/10\n",
      "Estimated mu value=0.9999642372131348\n",
      "LLL_train: -12041.0664 \t LLL_test: -1300.9243 \t         accuracy_train: 0.1213 \t accuracy_test: 0.1380 \t         Fold: 8/10\n",
      "Estimated mu value=0.9999556541442871\n",
      "LLL_train: -11998.3730 \t LLL_test: -1343.6195 \t         accuracy_train: 0.1247 \t accuracy_test: 0.1253 \t         Fold: 9/10\n",
      "Estimated mu value=0.9999555349349976\n",
      "LLL_train: -12015.8154 \t LLL_test: -1326.0393 \t         accuracy_train: 0.1247 \t accuracy_test: 0.1227 \t         Fold: 10/10\n",
      "Estimated mu value=0.999975323677063\n",
      "Train results mean: \n",
      "f1                 0.031642\n",
      "accuracy           0.123936\n",
      "MRR                0.253207\n",
      "top_3              0.260089\n",
      "top_5              0.368768\n",
      "top_10             0.570812\n",
      "error_d            7.365144\n",
      "error_d_avg        9.577108\n",
      "LLL           -12000.171875\n",
      "dtype: float64\n",
      "Test results mean: \n",
      "f1                0.032659\n",
      "accuracy          0.121419\n",
      "MRR               0.249621\n",
      "top_3             0.252996\n",
      "top_5             0.363737\n",
      "top_10            0.563839\n",
      "error_d           7.384161\n",
      "error_d_avg       9.584012\n",
      "LLL           -1342.049438\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set the training and evaluation procedure\n",
    "config = Config()\n",
    "config.num_hidden = 64\n",
    "config.dropout = 0\n",
    "config.optimizer = \"lbfgs\"  # one of [adam, sgd]\n",
    "config.lr = 0.1\n",
    "config.n_epoch = 20\n",
    "config.model = \"SCL\"  # or any other model name\n",
    "config.mode = \"disabled\"  # online or disabled\n",
    "config.seed = 100\n",
    "my_dataset = spatial_choice_dataset_interact\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "for i in range(10):\n",
    "    test_idx = np.arange(i, len(hh), 10)\n",
    "    train_idx = np.setdiff1d(np.arange(len(hh)), test_idx)\n",
    "    train_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[train_idx, :],\n",
    "        distance_to_work[train_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "    test_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[test_idx, :],\n",
    "        distance_to_work[test_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=len(train_dataset), shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=len(test_dataset), shuffle=False\n",
    "    )\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = SCL_Choice(train_dataset[0][0].shape[-1], edge_index).to(device)\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = train(\n",
    "        model,\n",
    "        criterion,\n",
    "        train_loader,\n",
    "        None,\n",
    "        test_loader,\n",
    "        config,\n",
    "        device,\n",
    "        verbose=False,\n",
    "    )\n",
    "    train_results.append(evaluate_nn(model, train_loader, comm))\n",
    "    test_results.append(evaluate_nn(model, test_loader, comm))\n",
    "\n",
    "    print(\n",
    "        f\"LLL_train: {train_results[-1]['LLL']:.4f} \\t LLL_test: {test_results[-1]['LLL']:.4f} \\t \\\n",
    "        accuracy_train: {train_results[-1]['accuracy']:.4f} \\t accuracy_test: {test_results[-1]['accuracy']:.4f} \\t \\\n",
    "        Fold: {i + 1}/10\"\n",
    "    )  # Log the results\n",
    "    print(f\"Estimated mu value={torch.sigmoid(model.mu_raw).detach().numpy()}\")\n",
    "\n",
    "train_results = {\n",
    "    key: [d[key] for d in train_results] for key in train_results[0].keys()\n",
    "}\n",
    "test_results = {key: [d[key] for d in test_results] for key in test_results[0].keys()}\n",
    "train_results = pd.DataFrame(train_results)\n",
    "test_results = pd.DataFrame(test_results)\n",
    "train_results.to_csv(f\"results/{config.model}_train_results.csv\", index=False)\n",
    "test_results.to_csv(f\"results/{config.model}_test_results.csv\", index=False)\n",
    "\n",
    "print(f\"Train results mean: \\n{train_results.mean()}\")\n",
    "print(f\"Test results mean: \\n{test_results.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLL_train: -11981.8496 \t LLL_test: -1360.5039 \t         accuracy_train: 0.1233 \t accuracy_test: 0.1094 \t         Fold: 1/10\n",
      "LLL_train: -11996.9863 \t LLL_test: -1344.0957 \t         accuracy_train: 0.1236 \t accuracy_test: 0.1094 \t         Fold: 2/10\n",
      "LLL_train: -11975.9414 \t LLL_test: -1366.6665 \t         accuracy_train: 0.1248 \t accuracy_test: 0.1224 \t         Fold: 3/10\n",
      "LLL_train: -11988.4287 \t LLL_test: -1354.8396 \t         accuracy_train: 0.1257 \t accuracy_test: 0.1224 \t         Fold: 4/10\n",
      "LLL_train: -12026.8516 \t LLL_test: -1315.6589 \t         accuracy_train: 0.1184 \t accuracy_test: 0.1484 \t         Fold: 5/10\n",
      "LLL_train: -11981.1875 \t LLL_test: -1360.4270 \t         accuracy_train: 0.1265 \t accuracy_test: 0.1016 \t         Fold: 6/10\n",
      "LLL_train: -11995.2070 \t LLL_test: -1347.7151 \t         accuracy_train: 0.1262 \t accuracy_test: 0.1146 \t         Fold: 7/10\n",
      "LLL_train: -12041.0664 \t LLL_test: -1300.9236 \t         accuracy_train: 0.1213 \t accuracy_test: 0.1380 \t         Fold: 8/10\n",
      "LLL_train: -11998.3730 \t LLL_test: -1343.6138 \t         accuracy_train: 0.1247 \t accuracy_test: 0.1253 \t         Fold: 9/10\n",
      "LLL_train: -12015.8145 \t LLL_test: -1326.0344 \t         accuracy_train: 0.1247 \t accuracy_test: 0.1227 \t         Fold: 10/10\n",
      "Train results mean: \n",
      "f1                 0.031642\n",
      "accuracy           0.123936\n",
      "MRR                0.253213\n",
      "top_3              0.260118\n",
      "top_5              0.368797\n",
      "top_10             0.570870\n",
      "error_d            7.365144\n",
      "error_d_avg        9.577115\n",
      "LLL           -12000.169922\n",
      "dtype: float64\n",
      "Test results mean: \n",
      "f1                0.032658\n",
      "accuracy          0.121419\n",
      "MRR               0.249626\n",
      "top_3             0.252996\n",
      "top_5             0.363737\n",
      "top_10            0.563839\n",
      "error_d           7.385442\n",
      "error_d_avg       9.584024\n",
      "LLL           -1342.047729\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set the training and evaluation procedure\n",
    "config = Config()\n",
    "config.num_hidden = 64\n",
    "config.dropout = 0\n",
    "config.optimizer = \"lbfgs\"  # one of [adam, sgd]\n",
    "config.lr = 0.1\n",
    "config.n_epoch = 20\n",
    "config.model = \"MNL\"  # or any other model name\n",
    "config.mode = \"disabled\"  # online or disabled\n",
    "config.seed = 100\n",
    "my_dataset = spatial_choice_dataset_interact\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "for i in range(10):\n",
    "    test_idx = np.arange(i, len(hh), 10)\n",
    "    train_idx = np.setdiff1d(np.arange(len(hh)), test_idx)\n",
    "    train_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[train_idx, :],\n",
    "        distance_to_work[train_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "    test_dataset = my_dataset(\n",
    "        comm,\n",
    "        hh.loc[test_idx, :],\n",
    "        distance_to_work[test_idx],\n",
    "        comm_features,\n",
    "        hh_features,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=len(train_dataset), shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=len(test_dataset), shuffle=False\n",
    "    )\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = MNL_Choice(train_dataset[0][0].shape[-1],\n",
    "                       train_dataset[0][0].shape[0]).to(device)\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    model = train(\n",
    "        model,\n",
    "        criterion,\n",
    "        train_loader,\n",
    "        None,\n",
    "        test_loader,\n",
    "        config,\n",
    "        device,\n",
    "        verbose=False,\n",
    "    )\n",
    "    train_results.append(evaluate_nn(model, train_loader, comm))\n",
    "    test_results.append(evaluate_nn(model, test_loader, comm))\n",
    "\n",
    "    print(\n",
    "        f\"LLL_train: {train_results[-1]['LLL']:.4f} \\t LLL_test: {test_results[-1]['LLL']:.4f} \\t \\\n",
    "        accuracy_train: {train_results[-1]['accuracy']:.4f} \\t accuracy_test: {test_results[-1]['accuracy']:.4f} \\t \\\n",
    "        Fold: {i + 1}/10\"\n",
    "    )  # Log the results\n",
    "\n",
    "train_results = {\n",
    "    key: [d[key] for d in train_results] for key in train_results[0].keys()\n",
    "}\n",
    "test_results = {key: [d[key] for d in test_results] for key in test_results[0].keys()}\n",
    "train_results = pd.DataFrame(train_results)\n",
    "test_results = pd.DataFrame(test_results)\n",
    "train_results.to_csv(f\"results/{config.model}_train_results.csv\", index=False)\n",
    "test_results.to_csv(f\"results/{config.model}_test_results.csv\", index=False)\n",
    "\n",
    "print(f\"Train results mean: \\n{train_results.mean()}\")\n",
    "print(f\"Test results mean: \\n{test_results.mean()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
